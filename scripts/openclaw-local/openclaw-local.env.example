# Local stack defaults for scripts/openclaw-local/run_openclaw_local_stack.sh

# vLLM core
MODEL=Qwen/Qwen3-8B
HOST=127.0.0.1
PORT=8000
API_KEY=sk-local
SERVED_MODEL_NAMES=qwen3-8b
MAX_MODEL_LEN=32768
GPU_MEMORY_UTILIZATION=0.90
ENABLE_SLEEP_MODE=1
# Dev mode exposes /sleep and /wake_up endpoints required by CLaaS feedback
VLLM_SERVER_DEV_MODE=1
ENABLE_AUTO_TOOL_CHOICE=1
TOOL_CALL_PARSER=qwen3_xml

# LoRA setup
LORA_NAME=openclaw/assistant
# Explicit modules: alias=/abs/path,alias2=/abs/path2
LORA_MODULES=
# Include aliases from CLaaS/.local_loras/.aliases.json
INCLUDE_ALIAS_LORAS=1
# Required for CLaaS feedback to hot-reload LoRA weights in vLLM
VLLM_ALLOW_RUNTIME_LORA_UPDATING=1

# CLaaS feedback API
CLAAS_API_PORT=8080

# Supervisor monitoring
MONITOR_INTERVAL_SECONDS=30
RESTART_BACKOFF_SECONDS=3
VLLM_HEALTH_URL=http://127.0.0.1:8000/health
VLLM_MODELS_URL=http://127.0.0.1:8000/v1/models
CLAAS_API_HEALTH_URL=http://127.0.0.1:8080/v1/health

# OpenClaw model mapping
MODEL_IDS=qwen3-8b,openclaw-assistant-latest
PRIMARY_MODEL=openclaw-assistant-latest
BASE_URL=http://127.0.0.1:8000/v1
